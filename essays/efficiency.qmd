---
title: "The Power of Efficiency"
format: html
editor: visual
---

As we’ve said in the class efficiency is a pivotal component of statistical computing (and data science). In this essay, give an explanation of what that term “efficiency” means in relation to statistical computing and describe some places where you encountered efficiency and understood its importance. Your essay should address the following questions:

-   What is the definition of “efficiency”?

-   What does efficiency look like in statistical computing / data science?

-   What does efficiency allow you to do?

-   Why is efficiency important?

-   Where did you encounter efficiency, and what were some [“a-ha” moments](https://www.merriam-webster.com/dictionary/aha%20moment) you had about efficiency? (For the latter, tie each a-ha moment to an artifact in the portfolio.)

My understanding of efficiency in statistical computing has changed over the course of this class. The way in which “efficient” is defined on dictionary.com is, “performing or functioning in the best possible manner with the least waste of time and effort”. While I would have agreed with this definition prior to this class, I know that I now interpret it very differently. Before this class, I would interpret this in a way that only considers the time and effort put into getting the result. Now, I see that while there are ways in R to quickly get your answer, the formatting of the output would be hard to understand, it’s harder to make changes, and you have to repeat the same steps over and over again across different variables. Efficiency takes these factors into consideration, and finds answers in ways that are clear, non-repeated, and reproducible.

Efficiency in statistical computing and data science is streamlining code to minimize time spent coding while maximizing the clarity and accuracy of results. This can look several ways in statistical computing and data science. One way that stands out to me is avoiding repeated code. When working in large datasets, it’s likely that you’ll want to perform an action across multiple variables or tables. Rather than repeating the same code, there are functions such as across(), including multiple statements within one function, or joins! These are tools that allow us to avoid more manual work, and allow R to apply functions across multiple objects. One way that I’ve grown in efficiency specifically is by learning new functions that help decrease the amount of steps in my data. Being a beginner in R, I was not aware of certain tools and functions that allow me to be less focused on manually searching through datasets or doing arithmetic in R, but streamline the process!

Efficiency allows for scalability and predictability. As projects grow in scope, efficient practices make sure that results remain trustworthy even when datasets increase in size or complexity. One of our learning targets, R-3, mentions being able to write robust programs that are resistant to changes in inputs. This is a key part of efficiency in statistical computing, because rather than continuously editing your code based on how large your dataset is, or what specific tables you’re dealing with, you can focus on the insights and adding code to further explore. For example, a data scientist working in one pipeline can easily adapt it to handle more data without drastic changes. Efficiency also allows individuals to better collaborate. Efficient code is more readable and maintainable, making it easier for teams to work together. From doing peer reviews in this class, I realized that the student’s work I was reviewing utilized efficient practices, which made it simpler for me to review and understand. Rather than having to take long periods of time reading through repeated or confusing code, I was better able to collaborate and find more conceptual pieces of feedback. 

Efficiency is important because it impacts the quality and timeliness of insights. In a time where data is growing exponentially, inefficient practices can quickly become unmanageable, wasting time and resources. The ability to process and analyze data efficiently can provide a competitive edge to someone, especially for businesses that rely on data analysis for decision-making. Data is only going to become more complex. By understanding how to deal with data in an efficient way, we will be prepared to deal with even larger and messier datasets.

I have encountered personal growth in efficiency throughout this course. The first is related to learning new, more efficient tools. In Lab 4 Question 5 (PE-4), to find the lowest median full-time median weekly price for center-based childcare for infants, I originally utilized arrange() and slice() functions to find the lowest. Instead of using two separate steps, I learned from my feedback that it is more efficient to do this in one step, using the slice_min() function. A second way that I became more efficient was by avoiding repeating code. Originally in Lab 5 where I’m finding the initial suspect (WD-5) , I used the filter() function three times! I’ve learned how powerful the filter() function is and instead of repeating it, you can include several filter statements in one function! 

Learning about efficiency in statistical computing has made me more intentional in my coding. Even though it has been a learning curve that has taken time, it will take less time for me to code moving forward because I’ll be dealing less with redundant code, and more time finding insights!
